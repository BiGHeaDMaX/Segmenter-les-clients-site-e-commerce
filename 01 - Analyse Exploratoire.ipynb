{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analyse Exploratoire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliothèques de base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utilisés lors de l'ACP\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Servira pour faire l'ANOVA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Pour faire tests de normalité\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Utilisé pour passer des données au log avant ANOVA\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Utilisé pour savoir si le fichier excel d'export existe déjà\n",
    "import os\n",
    "\n",
    "# Je désactive le copy warning, en m'étant au préalable assuré que les traitements étaient corrects\n",
    "# pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importation des datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importation terminée\n"
     ]
    }
   ],
   "source": [
    "customers = pd.read_csv(\"dataset\\olist_customers_dataset.csv\", sep=',')\n",
    "geolocation = pd.read_csv(\"dataset\\olist_geolocation_dataset.csv\", sep=',')\n",
    "order_items = pd.read_csv(\"dataset\\olist_order_items_dataset.csv\", sep=',')\n",
    "order_payments = pd.read_csv(\"dataset\\olist_order_payments_dataset.csv\", sep=',')\n",
    "order_reviews = pd.read_csv(\"dataset\\olist_order_reviews_dataset.csv\", sep=',')\n",
    "orders = pd.read_csv(\"dataset\\olist_orders_dataset.csv\", sep=',')\n",
    "products = pd.read_csv(\"dataset\\olist_products_dataset.csv\", sep=',')\n",
    "sellers = pd.read_csv(\"dataset\\olist_sellers_dataset.csv\", sep=',')\n",
    "product_category_name_translation = pd.read_csv(\"dataset\\product_category_name_translation.csv\", sep=',')\n",
    "\n",
    "print('Importation terminée')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pré-traitement des datasets avant fusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traitement de *geolocation***\n",
    "\n",
    "Je supprime *geolocation_city* et *geolocation_state* que je ne vais pas utiliser.<br>\n",
    "Je regroupe par *geolocation_zip_code_prefix* en faisant la moyen pour les coordonnées GPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes avant traitement : 1000163\n",
      "Lignes après traitement : 19015\n",
      "Valeurs manquantes : 0\n"
     ]
    }
   ],
   "source": [
    "print('Lignes avant traitement :', len(geolocation))\n",
    "geolocation = geolocation.drop(['geolocation_city', 'geolocation_state'], axis=1)\n",
    "geolocation = geolocation.groupby('geolocation_zip_code_prefix').mean()\n",
    "geolocation = geolocation.reset_index() # pour remettre geolocation_zip_code_prefix en tant que colonne\n",
    "print('Lignes après traitement :', len(geolocation))\n",
    "print('Valeurs manquantes :', geolocation.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traitement de *customers***\n",
    "\n",
    "Je fusionne avec *geolocation* pour récupérer les coordonnées GPS à partir du zip code prefix<br>\n",
    "Je renomme *geolocation_lat* et *geolocation_lng* en *customer_lat* et *customer_lng*<br>\n",
    "Je ne conserve au final que *customer_id*, *customer_unique_id*, *customer_lat* et *customer_lng*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes : 0\n"
     ]
    }
   ],
   "source": [
    "customers = customers.merge(geolocation, left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')\n",
    "customers.rename(columns={\"geolocation_lat\": \"customer_lat\", \"geolocation_lng\": \"customer_lng\"}, inplace=True)\n",
    "customers = customers[['customer_id', 'customer_unique_id', 'customer_lat', 'customer_lng']]\n",
    "# Il y a quelques valeurs manquantes dans customer_lat/customer_lng : j'impute par la moyenne\n",
    "customers['customer_lat'].loc[customers['customer_lat'].isnull() == True] = customers['customer_lat'].mean()\n",
    "customers['customer_lng'].loc[customers['customer_lng'].isnull() == True] = customers['customer_lng'].mean()\n",
    "print('Valeurs manquantes :', customers.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traitement de *sellers***\n",
    "\n",
    "Je fusionne avec *geolocation* pour récupérer les coordonnées GPS à partir du zip code prefix<br>\n",
    "Je renomme *geolocation_lat* et *geolocation_lng* en *seller_lat* et *seller_lng*<br>\n",
    "Je ne conserve au final que *seller_id*, *seller_lat*, et *seller_lng*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes : 0\n"
     ]
    }
   ],
   "source": [
    "sellers = sellers.merge(geolocation, left_on='seller_zip_code_prefix', right_on='geolocation_zip_code_prefix', how='left')\n",
    "sellers.rename(columns={\"geolocation_lat\": \"seller_lat\", \"geolocation_lng\": \"seller_lng\"}, inplace=True)\n",
    "sellers = sellers[['seller_id', 'seller_lat', 'seller_lng']]\n",
    "# Il y a quelques valeurs manquantes dans seller_lat/seller_lng : j'impute par la moyenne\n",
    "sellers['seller_lat'].loc[sellers['seller_lat'].isnull() == True] = sellers['seller_lat'].mean()\n",
    "sellers['seller_lng'].loc[sellers['seller_lng'].isnull() == True] = sellers['seller_lng'].mean()\n",
    "print('Valeurs manquantes :', sellers.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traitement de *order_items***\n",
    "\n",
    "Je regroupe par numéro de commande (order_id), les autres colonnes sont agglomérées comme suit : \n",
    "- *order_item_id* : *max()*, ce qui donnera le nombre d'articles de la commande\n",
    "- *product_id* : *first()*, je ne conserve que le premier, pas idéal mais ça ne concerne qu'un nombre très limité de commandes\n",
    "- *seller_id* : *first()*, même logique que pour *product_id*\n",
    "- *shipping_limit_date* : *first()*, c'est la même pour toute la commande\n",
    "- *price* : *sum()*, prix total des articles\n",
    "- *freight_value* : *mean()*, frais de port moyens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes avant traitement : 112650\n",
      "Lignes après traitement : 98666\n",
      "Valeurs manquantes : 0\n"
     ]
    }
   ],
   "source": [
    "print('Lignes avant traitement :', len(order_items))\n",
    "order_items = order_items.groupby('order_id').agg({'order_item_id': 'max', 'product_id': 'first', 'seller_id': 'first', 'shipping_limit_date': 'first', 'price': 'sum', 'freight_value': 'mean'})\n",
    "order_items = order_items.reset_index() # pour remettre order_id en tant que colonne\n",
    "print('Lignes après traitement :', len(order_items))\n",
    "print('Valeurs manquantes :', order_items.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traitement de *order_payments***\n",
    "\n",
    "Je supprime *payment_sequential*, que je ne vais pas utiliser.<br>\n",
    "Je regroupe par *order_id*, les autres colonnes sont agglomérées comme suit : \n",
    "- *payment_type* : *first()*\n",
    "- *payment_installments* (paiements en plusieurs fois) : *max()*\n",
    "- *payment_value* : *sum()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes avant traitement : 103886\n",
      "Lignes après traitement : 99440\n",
      "Valeurs manquantes : 0\n"
     ]
    }
   ],
   "source": [
    "print('Lignes avant traitement :', len(order_payments))\n",
    "order_payments = order_payments.drop(['payment_sequential'], axis=1)\n",
    "order_payments = order_payments.groupby('order_id').agg({'payment_type': 'first', 'payment_installments': 'max', 'payment_value': 'sum'})\n",
    "order_payments = order_payments.reset_index() # pour remettre order_id en tant que colonne\n",
    "print('Lignes après traitement :', len(order_payments))\n",
    "print('Valeurs manquantes :', order_payments.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traitement de *order_reviews***\n",
    "\n",
    "Je supprime *review_id*, *review_comment_title*, *review_comment_message*, *review_creation_date* et *review_answer_timestamp*, que je n'utiliserai pas.<br>\n",
    "Je regroupe par *order_id* avec *mean()* sur *review_score* (il arrive parfois qu'il y ait plusieurs avis pour une même commande)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes avant traitement : 99224\n",
      "Lignes après traitement : 98673\n",
      "Valeurs manquantes : 0\n"
     ]
    }
   ],
   "source": [
    "print('Lignes avant traitement :', len(order_reviews))\n",
    "order_reviews = order_reviews.drop(['review_id', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp'], axis=1)\n",
    "order_reviews = order_reviews.groupby('order_id').mean()\n",
    "order_reviews = order_reviews.reset_index() # pour remettre order_id en tant que colonne\n",
    "print('Lignes après traitement :', len(order_reviews))\n",
    "print('Valeurs manquantes :', order_reviews.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traitement de *orders***\n",
    "\n",
    "Je convertis les colonnes contenant des dates que je vais utiliser au format date.<br>\n",
    "Je décide de ne conserver que les commandes qui sont indiquées comme livrées (la grande majorité)<br>\n",
    "Je crée une nouvelle colonne *delivery_time* en faisant la différence entre *order_purchase_timestamp* et *order_delivered_customer_date*.<br>\n",
    "Au final, je ne conserve que *order_id*, *customer_id*, *order_purchase_timestamp* et *delivery_time*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes avant traitement : 99441\n",
      "Lignes après traitement : 96470\n",
      "Valeurs manquantes : 0\n"
     ]
    }
   ],
   "source": [
    "print('Lignes avant traitement :', len(orders))\n",
    "# je passe par .apply() pour appliquer pd.to_datetime au deux colonnes\n",
    "orders[['order_purchase_timestamp', 'order_delivered_customer_date']] = orders[['order_purchase_timestamp', 'order_delivered_customer_date']].apply(pd.to_datetime, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "orders = orders.loc[orders['order_status'] == 'delivered']\n",
    "orders['delivery_time'] = (orders['order_delivered_customer_date'] - orders['order_purchase_timestamp']).dt.days\n",
    "orders = orders[['order_id', 'customer_id', 'order_purchase_timestamp', 'delivery_time']]\n",
    "# Je supprime les quelques lignes où delivery_time est manquant\n",
    "orders = orders.loc[orders['delivery_time'].isnull() == False]\n",
    "print('Lignes après traitement :', len(orders))\n",
    "print('Valeurs manquantes :', orders.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Traitement de *products***\n",
    "\n",
    "Je fusionne avec *product_category_name_translation* pour avoir les catégories en Anglais.<br>\n",
    "Je remplace les valeurs manquantes dans *product_category_name_english* par \"other\".<br>\n",
    "Au final, je ne conserve que les colonnes *product_id* et *product_category_name_english*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Data Science\\AppData\\Local\\Temp\\ipykernel_17288\\1600838163.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  products['product_category_name_english'].loc[products['product_category_name_english'].isnull() == True] = \"other\"\n"
     ]
    }
   ],
   "source": [
    "products = products.merge(product_category_name_translation, on='product_category_name', how='left')\n",
    "products['product_category_name_english'].loc[products['product_category_name_english'].isnull() == True] = \"other\"\n",
    "products = products[['product_id', 'product_category_name_english']]\n",
    "print('Valeurs manquantes :', products.isnull().sum().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
